{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 2: EDA for the Women in STEM dataset\n",
    "\n",
    "Data: https://github.com/fivethirtyeight/data/blob/master/college-majors/women-stem.csv\n",
    "\n",
    "History\n",
    "\n",
    "Data is originally from American Community Survey 2010-2012 Public Use Microdata Series. The dataset consists of 75 STEM major studies divided into 5 categories. It also gives the number of men and women in each major along with the median salary and the proportion of women(ShareWomen) in each STEM major.\n",
    "\n",
    "Exercise\n",
    "\n",
    "Submit the work as a course: 50 points\n",
    "Export it to GitHub/Submit as lab: 10 points\n",
    "Perform data cleaning and explanatory data analysis on this dataset. 10 points\n",
    "Provide visualizations and derive conclusions. 20 points\n",
    "Split the dataset into training and testing at 80:20 ratio. Use random seed = 12345. 10 Points\n",
    "Fit a linear regression model to predict the ShareWomen. Use model name stem_model. Bonus +10 points\n",
    "Predict ShareWomen using the model and calculate mean squared error for training and testing datasets. +10 points Level: Medium\n",
    "Use the following variable names\n",
    "\n",
    "Model name stem_model.\n",
    "MSE_Train, MSE_Test for the mean squared error and Pred_Test for predictions on the test dataset.\n",
    "Naming Convention:\n",
    "\n",
    "Name your Python file as \"Team Name\"_stem_women\n",
    "\n",
    "#### In this model we will be performing the below analysis\n",
    "1. exploratory analysis\n",
    "2. Data Visualisation\n",
    "3. Check for the variation in variables, i.e. we would be checking for the interdependence\n",
    "4. Check for fit of different models and check for over-fitting and bias\n",
    "\n",
    "#### Import few packages to aid us in performing linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "UsageError: unrecognized arguments: # to plot graphs in browser or as output file.\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns     # to be used for plotting\n",
    "import matplotlib.pyplot as plt   # to be used as base for plotting\n",
    "import pandas as pd  #to load data frame efficiently and manipulate data\n",
    "import numpy as np    # to perform aggregate analysis on different variables\n",
    "from sklearn.cross_validation import train_test_split    # to run linear models and to divide data in test and train \n",
    "from sklearn import linear_model as lm # to import linear model \n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline # to make pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso\n",
    "%matplotlib inline   # to plot graphs in browser or as output file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Seaborn, Pandas, matplotlib, numpy, linear_model, metric from sklearn and any other useful package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Continue...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is assertion block which verifies the solution.\n",
    "\n",
    "try:\n",
    "    def verify_answer():\n",
    "        return True\n",
    "\n",
    "    ref_assert_var = verify_answer()\n",
    "except Exception as e: \n",
    "    print('Your assertion block throws error: ' + str(e))\n",
    "else:\n",
    "    if ref_assert_var:\n",
    "        print('continue')\n",
    "    else:\n",
    "        print('The answer did not pass the test.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataframe as stem_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_model = pd.read_csv('https://raw.githubusercontent.com/fivethirtyeight/data/master/college-majors/women-stem.csv')  # read the file into the file name assigned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_model.head()   # printing the head of 5 lines to verify the data is loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is assertion block which verifies the solution.\n",
    "\n",
    "try:\n",
    "    def verify_answer():\n",
    "        \"\"\"\n",
    "        enter your verification code here.\n",
    "        return true if your checks pass\n",
    "        eg: \n",
    "        if above_user_answer_var > 100: \n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        if stem_model['Major_code'].iloc[3] == 2417:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    ref_assert_var = verify_answer()\n",
    "except Exception as e: \n",
    "    print('Your assertion block throws error: ' + str(e))\n",
    "else:\n",
    "    if ref_assert_var:\n",
    "        print('continue')\n",
    "    else:\n",
    "        print('The answer did not pass the test.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the Exploratory Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stem_model.info(),\"\\n\") # basic info about the dataframe\n",
    "print(stem_model.dtypes,\"\\n\")\n",
    "print(\"Number of unique majors:\", stem_model['Major_category'].nunique(),\"\\n\")\n",
    "print(\"There names are:\", stem_model['Major_category'].unique(),\"\\n\")\n",
    "count_of_major = stem_model['Major'].nunique()\n",
    "print(\"Different Majors are:\", stem_model['Major'].nunique(),\"\\n\")\n",
    "print(stem_model['Major'],\"\\n\")\n",
    "print(sum(np.round(stem_model['Women']/stem_model['Total'],4) == np.round(stem_model['ShareWomen'],4)),\"\\n\") # to check whether total = women + men \n",
    "print(sum(stem_model['Total'] == stem_model['Women']+stem_model['Men']),\"\\n\") # to check whether women/total = ShareWomen\n",
    "print(np.sum(stem_model.isnull()),\"\\n\") # no missing value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Use \"count_of_major\" to print count of Majors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_of_major = stem_model['Major'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is assertion block which verifies the solution.\n",
    "\n",
    "try:\n",
    "    def verify_answer():\n",
    "        \"\"\"\n",
    "        enter your verification code here.\n",
    "        return true if your checks pass\n",
    "        eg: \n",
    "        if above_user_answer_var > 100: \n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \"\"\"\n",
    "        if count_of_major == 76:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    ref_assert_var = verify_answer()\n",
    "except Exception as e: \n",
    "    print('Your assertion block throws error: ' + str(e))\n",
    "else:\n",
    "    if ref_assert_var:\n",
    "        print('continue')\n",
    "    else:\n",
    "        print('The answer did not pass the test.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations\n",
    "now make some visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, axes = plt.subplots(7,1)\n",
    "axes[0] = plt.plot(stem_model['ShareWomen'], 'r.');\n",
    "axes[1] = sns.boxplot(stem_model['ShareWomen']);\n",
    "axes[2] = sns.pairplot(stem_model, hue='Major_category',size=2.5); # plotting various scatter plots for checking how each variables behaves against other variables\n",
    "axes[3] = sns.regplot(stem_model['Rank'],stem_model['ShareWomen']);\n",
    "axes[4] = sns.regplot(stem_model['Total'],stem_model['ShareWomen']);\n",
    "axes[5] = sns.regplot(stem_model['Men'],stem_model['ShareWomen']);\n",
    "axes[6] = sns.regplot(stem_model['Men'],stem_model['Median']);\n",
    "#### In the ShareWomen category, each major is distinctly differentiated when plotted agains against other variables.\n",
    "#so we can say that Rank, Major_category are usefull variables\n",
    "fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw scatter plot, box plots and other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is assertion block which verifies the solution.\n",
    "\n",
    "try:\n",
    "    def verify_answer():\n",
    "        \"\"\"\n",
    "        enter your verification code here.\n",
    "        return true if your checks pass\n",
    "        eg: \n",
    "        if above_user_answer_var > 100: \n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \"\"\"\n",
    "        if 76 == 76:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    ref_assert_var = verify_answer()\n",
    "except Exception as e: \n",
    "    print('Your assertion block throws error: ' + str(e))\n",
    "else:\n",
    "    if ref_assert_var:\n",
    "        print('continue')\n",
    "    else:\n",
    "        print('The answer did not pass the test.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now making the dummy vairables for Major_category ategorical data and store it in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = stem_model.join(pd.get_dummies(stem_model['Major_category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use get_dummies method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is assertion block which verifies the solution.\n",
    "\n",
    "try:\n",
    "    def verify_answer():\n",
    "        \"\"\"\n",
    "        enter your verification code here.\n",
    "        return true if your checks pass\n",
    "        eg: \n",
    "        if above_user_answer_var > 100: \n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \"\"\"\n",
    "        if df['Engineering'].iloc[0] == 1:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    ref_assert_var = verify_answer()\n",
    "except Exception as e: \n",
    "    print('Your assertion block throws error: ' + str(e))\n",
    "else:\n",
    "    if ref_assert_var:\n",
    "        print('continue')\n",
    "    else:\n",
    "        print('The answer did not pass the test.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now run the simple Linear Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Major_category','Major','Biology & Life Science'], axis=1, inplace = True)\n",
    "model = lm.LinearRegression(fit_intercept=True)\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(df.drop(['ShareWomen','Men','Women','Total','Median'], axis=1), df['ShareWomen'], random_state=12345,train_size=0.8)\n",
    "# dividing the data in train and test data \n",
    "\n",
    "model.fit(Xtrain.values, ytrain) # running the model to fit or train the model\n",
    "Xfit = model.predict(Xtrain.values) # saving the predicted for train data\n",
    "yfit = model.predict(Xtest) # saving predicted values for test data\n",
    "print(\"Model Coefficents\", model.coef_) # to print the coefficients of the each variable\n",
    "print(\"Model Intercept\",model.intercept_) # to print the intercept\n",
    "Pred_Test  = yfit; #\n",
    "%matplotlib notebook\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1,len(ytest)+1), ytest, alpha =0.5, color='r',label ='Actual')\n",
    "plt.plot(range(1,len(yfit)+1), yfit, alpha =0.5, color='b', label ='Predicted')\n",
    "\n",
    "plt.legend()\n",
    "MSE_Test = np.round(metrics.mean_squared_error(ytest, yfit, multioutput = 'raw_values')[0],4)\n",
    "MSE_Train = np.round(metrics.mean_squared_error(ytrain, Xfit, multioutput = 'raw_values')[0],4)\n",
    "print(\"MSE for train data:\",MSE_Train)\n",
    "print(\"MSE for test data:\",MSE_Test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use lm.LinearRegression to create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MSE_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is assertion block which verifies the solution.\n",
    "\n",
    "try:\n",
    "    def verify_answer():\n",
    "        \"\"\"\n",
    "        enter your verification code here.\n",
    "        return true if your checks pass\n",
    "        eg: \n",
    "        if above_user_answer_var > 100: \n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \"\"\"\n",
    "        if (MSE_Train > 0.0088) and (MSE_Train < 0.0098):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    ref_assert_var = verify_answer()\n",
    "except Exception as e: \n",
    "    print('Your assertion block throws error: ' + str(e))\n",
    "else:\n",
    "    if ref_assert_var:\n",
    "        print('continue')\n",
    "    else:\n",
    "        print('The answer did not pass the test.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now run lm with polynomial regression with lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polymodel = make_pipeline(PolynomialFeatures(3),lm.LinearRegression(fit_intercept =True))\n",
    "\n",
    "polymodel.fit(Xtrain.values,ytrain)\n",
    "yfit_poly = polymodel.predict(Xtest.values)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "print(polymodel.score(Xtrain.values, ytrain))\n",
    "\n",
    "\n",
    "poly_MSE_Test = metrics.mean_squared_error(ytest, yfit_poly)\n",
    "%matplotlib notebook\n",
    "plt.figure()\n",
    "plt.plot(range(1,len(ytest)+1), ytest, alpha =0.5 ,color='r',label ='Actual')\n",
    "plt.plot(range(1,len(yfit_poly)+1), yfit_poly, alpha =0.5, color='b', label ='Predicted')\n",
    "#plt.errorbar?\n",
    "plt.errorbar(range(1,len(yfit_poly)+1), yfit_poly, yerr= yfit_poly-ytest, ecolor='grey', alpha = 0.7, capthick =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be used to improvise on model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(poly_MSE_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is assertion block which verifies the solution.\n",
    "\n",
    "try:\n",
    "    def verify_answer():\n",
    "        \"\"\"\n",
    "        enter your verification code here.\n",
    "        return true if your checks pass\n",
    "        eg: \n",
    "        if above_user_answer_var > 100: \n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \"\"\"\n",
    "        if (poly_MSE_Test > 0.06) and (poly_MSE_Test < .15):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    ref_assert_var = verify_answer()\n",
    "except Exception as e: \n",
    "    print('Your assertion block throws error: ' + str(e))\n",
    "else:\n",
    "    if ref_assert_var:\n",
    "        print('continue')\n",
    "    else:\n",
    "        print('The answer did not pass the test.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now run the Lasso regression as the above model is overfitting, projecting data to 3d space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "polymodel = make_pipeline(PolynomialFeatures(3),Lasso(0.025))\n",
    "\n",
    "polymodel.fit(Xtrain.values,ytrain)\n",
    "yfit_poly = polymodel.predict(Xtest.values)\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1,len(ytest)+1), ytest, alpha =0.5 ,color='r',label ='Actual')\n",
    "plt.plot(range(1,len(yfit_poly)+1), yfit_poly, alpha =0.5, color='b', label ='Predicted')\n",
    "#plt.errorbar?\n",
    "plt.errorbar(range(1,len(yfit_poly)+1), yfit_poly, yerr= yfit_poly-ytest, ecolor='grey', alpha = 0.7, capthick =1)\n",
    "\n",
    "plt.legend()\n",
    "print(polymodel.score(Xtrain.values, ytrain))\n",
    "\n",
    "\n",
    "poly_MSE_Test = metrics.mean_squared_error(ytest, yfit_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use \"Lasso(0.025)\" in place of lm.LinearRegression(fit_intercept =True) in   make_pipeline(PolynomialFeatures(3),lm.LinearRegression(fit_intercept =True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_MSE_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is assertion block which verifies the solution.\n",
    "\n",
    "try:\n",
    "    def verify_answer():\n",
    "        \"\"\"\n",
    "        enter your verification code here.\n",
    "        return true if your checks pass\n",
    "        eg: \n",
    "        if above_user_answer_var > 100: \n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \"\"\"\n",
    "        if (poly_MSE_Test > 0.0065) and (poly_MSE_Test < .065):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    ref_assert_var = verify_answer()\n",
    "except Exception as e: \n",
    "    print('Your assertion block throws error: ' + str(e))\n",
    "else:\n",
    "    if ref_assert_var:\n",
    "        print('continue')\n",
    "    else:\n",
    "        print('The answer did not pass the test.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
